

### âœ… `README.md`

````markdown
# ðŸ¤– Local DeepSeek LLM Python Assistant

This project is a **locally-hosted AI code assistant and document Q&A system** powered by **DeepSeek LLMs** using **Ollama** and **LangChain**. It provides two core features:

---

## ðŸš€ Features

### 1. ðŸ§  DeepSeek Code Companion
> Your AI pair programmer

- Chat-based Python coding assistant
- Model options: `deepseek-r1:1.5b` and `deepseek-r1:3b`
- Built-in debugging advice and solution generation
- Powered by **LangChain**, **Ollama**, and **Streamlit**

---

### 2. ðŸ“˜ DocuMind AI
> An intelligent PDF reader for research or technical documents

- Upload a PDF, and ask questions about its content
- Embeds documents using `deepseek-r1:1.5b` embeddings
- Answers queries using contextual retrieval and LLM generation
- Fully local and private

---

## ðŸ› ï¸ Problem This Solves

Many developers and researchers want to use AI locally for:
- Writing and debugging Python code
- Asking intelligent questions about technical PDFs

But most solutions are cloud-based and expensive. This project brings **high-quality LLM capabilities fully offline** using **Ollama**.

---

## âš™ï¸ Setup Instructions

### ðŸ“¦ 1. Install Dependencies

Make sure you have Python 3.10+ and [Ollama](https://ollama.ai/) installed locally.

```bash
pip install -r requirements.txt
````

### ðŸ’¡ 2. Pull the DeepSeek Models

Install the models into Ollama (this may take a few minutes):

```bash
ollama pull deepseek-coder:1.5b
ollama pull deepseek-coder:3b
```

> If you're using `deepseek-r1`, adjust commands accordingly.

---

### ðŸ§ª 3. Run the Apps

There are two Streamlit apps:

#### 1. Run Code Companion

```bash
streamlit run app.py
```

#### 2. Run Document Q\&A

```bash
streamlit run rag.py
```

---

## ðŸ“‚ Folder Structure

```bash
â”œâ”€â”€ app.py                    # Code companion chatbot
â”œâ”€â”€ rag.py                    # Document Q&A system
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Document_Store/
â”‚   â””â”€â”€ your_pdf.pdf          # Folder to store uploaded PDFs
```

---

## ðŸ“Œ Notes

* Ollama should be running locally on `http://localhost:11434`
* Ensure DeepSeek models are downloaded before running the app
* Works offline once models are downloaded
* Tested with `deepseek-r1:1.5b` and `deepseek-r1:3b`

---

## ðŸ™Œ Credits

Built with:

* [LangChain](https://www.langchain.com/)
* [Streamlit](https://streamlit.io/)
* [Ollama](https://ollama.ai/)
* [DeepSeek LLMs](https://github.com/deepseek-ai)

---

## ðŸ“œ License

MIT License


Let me know if you want me to add images, badges, or a video demo section.
